{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Azure Machine Learning SDK\n",
    "\n",
    "## Contents\n",
    "____\n",
    "**1. [Workspace](#Workspace)**\n",
    "\n",
    "- 1.1 Create a Workspace and write config.json\n",
    "- 1.2 Connect to Workspace with config.json\n",
    "- 1.3 Connect to Workspace with variable\n",
    "- 1.4 Get details of the Workspace\n",
    "\n",
    "**2. [Experiment](#Experiment)**\n",
    "\n",
    "- 2.1 Create/Get Experiment\n",
    "\n",
    "**3.  [Run](#Run) **\n",
    "\n",
    "- 3.1 Create a run object in the experiment and start logging\n",
    "- 3.2 Track different metrics\n",
    "\n",
    "**4. [Model](#Model)**\n",
    "\n",
    "- 4.1 Register Model\n",
    "- 4.2 Download Model\n",
    "- 4.3 Delete Model\n",
    "\n",
    "**5. [ComputeTarget, RunConfiguration, and ScriptRunConfig](#ComputeTarget,RunConfiguration,andScriptRunConfig)**\n",
    "\n",
    "- 5.1 Setting up an AmlCompute (child class of ComputeTarget)\n",
    "- 5.2 Create a Compute Target\n",
    "\n",
    "___\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Workspace\n",
    "\n",
    "### 1.1 Create a Workspace and write config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Experiment, Workspace\n",
    "\n",
    "ws = Workspace.create(name='myworkspace',\n",
    "            subscription_id='<azure-subscription-id>',\n",
    "            resource_group='myresourcegroup',\n",
    "            create_resource_group=True,\n",
    "            location='eastus2'\n",
    "            )\n",
    "            \n",
    "ws.write_config(path=\"./file-path\", file_name=\"ws_config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Connect to Workspace with config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto with exception (azureml-core 1.3.0 (c:\\programdata\\anaconda3\\lib\\site-packages), Requirement.parse('azureml-core==1.0.72.*')).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.ReusedStepRun = azureml.pipeline.core.run:StepRun._from_reused_dto with exception (azureml-core 1.3.0 (c:\\programdata\\anaconda3\\lib\\site-packages), Requirement.parse('azureml-core==1.0.72.*')).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.StepRun = azureml.pipeline.core.run:StepRun._from_dto with exception (azureml-core 1.3.0 (c:\\programdata\\anaconda3\\lib\\site-packages), Requirement.parse('azureml-core==1.0.72.*')).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint hyperdrive = azureml.train.hyperdrive:HyperDriveRun._from_run_dto with exception (azureml-core 1.3.0 (c:\\programdata\\anaconda3\\lib\\site-packages), Requirement.parse('azureml-core==1.0.72.*')).\nThis notebook was created using version 1.0.2 of the Azure ML SDK\nYou are currently using version 1.3.0 of the Azure ML SDK\n\nWorkspace name: data-science\nAzure region: westeurope\nSubscription id: 29b64be4-867b-40ee-a259-b58b97bfc26f\nResource group: data-science\n"
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Experiment, Workspace\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"This notebook was created using version 1.0.2 of the Azure ML SDK\")\n",
    "print(\"You are currently using version\", azureml.core.VERSION, \"of the Azure ML SDK\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Connect to Workspace with variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto with exception (azureml-core 1.3.0 (c:\\programdata\\anaconda3\\lib\\site-packages), Requirement.parse('azureml-core==1.0.72.*')).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.ReusedStepRun = azureml.pipeline.core.run:StepRun._from_reused_dto with exception (azureml-core 1.3.0 (c:\\programdata\\anaconda3\\lib\\site-packages), Requirement.parse('azureml-core==1.0.72.*')).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.StepRun = azureml.pipeline.core.run:StepRun._from_dto with exception (azureml-core 1.3.0 (c:\\programdata\\anaconda3\\lib\\site-packages), Requirement.parse('azureml-core==1.0.72.*')).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint hyperdrive = azureml.train.hyperdrive:HyperDriveRun._from_run_dto with exception (azureml-telemetry 1.3.0 (c:\\programdata\\anaconda3\\lib\\site-packages), Requirement.parse('azureml-telemetry==1.0.72.*')).\n"
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Experiment, Workspace\n",
    "\n",
    "subscription_id = \"29b64be4-867b-40ee-a259-b58b97bfc26f\"\n",
    "resource_group = \"data-science\"\n",
    "workspace_name = \"data-science\"\n",
    "\n",
    "ws = Workspace.get(name = workspace_name,\n",
    "            subscription_id = subscription_id,\n",
    "            resource_group = resource_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Get details of the Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'id': '/subscriptions/29b64be4-867b-40ee-a259-b58b97bfc26f/resourceGroups/data-science/providers/Microsoft.MachineLearningServices/workspaces/data-science',\n 'name': 'data-science',\n 'location': 'westeurope',\n 'type': 'Microsoft.MachineLearningServices/workspaces',\n 'tags': {},\n 'sku': 'Enterprise',\n 'workspaceid': 'f3a18bbf-44bc-4e31-8355-3f8576fb0639',\n 'description': '',\n 'friendlyName': '',\n 'creationTime': '2020-04-03T09:06:14.2884876+00:00',\n 'containerRegistry': '/subscriptions/29b64be4-867b-40ee-a259-b58b97bfc26f/resourceGroups/data-science/providers/Microsoft.ContainerRegistry/registries/datascience0b4c9695',\n 'keyVault': '/subscriptions/29b64be4-867b-40ee-a259-b58b97bfc26f/resourcegroups/data-science/providers/microsoft.keyvault/vaults/datascience6891748158',\n 'applicationInsights': '/subscriptions/29b64be4-867b-40ee-a259-b58b97bfc26f/resourcegroups/data-science/providers/microsoft.insights/components/datascience9934152387',\n 'identityPrincipalId': '8fd0b713-8c03-427a-9068-1e9e62a812fc',\n 'identityTenantId': '72f988bf-86f1-41af-91ab-2d7cd011db47',\n 'identityType': 'SystemAssigned',\n 'storageAccount': '/subscriptions/29b64be4-867b-40ee-a259-b58b97bfc26f/resourcegroups/data-science/providers/microsoft.storage/storageaccounts/datascience2875229037'}"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "ws.get_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 2. Experiment\n",
    "\n",
    "### 2.1 Create/Get Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Experiment(Name: esprit,\nWorkspace: data-science)",
      "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>esprit</td><td>data-science</td><td><a href=\"https://ml.azure.com/experiments/esprit?wsid=/subscriptions/29b64be4-867b-40ee-a259-b58b97bfc26f/resourcegroups/data-science/workspaces/data-science\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "experiment = Experiment(workspace=ws, name=\"esprit\")\n",
    "experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## 3. Run\n",
    "\n",
    "### 3.1 Create a run object in the experiment and start logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "run =  experiment.start_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scalar\n",
    "run.log('accuracy', 0.03)\n",
    "# List \n",
    "run.log_list(\"accuracies\", [0.6, 0.7, 0.87])\n",
    "# Row\n",
    "run.log_row(\"Y over X\", x=1, y=0.4)\n",
    "# Table \n",
    "run.log_table(\"Y over X\", {\"x\":[1, 2, 3], \"y\":[0.6, 0.7, 0.89]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "No Skill: ROC AUC=0.500\nLogistic: ROC AUC=0.903\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# roc curve and auc\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "# generate 2 class dataset\n",
    "X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)\n",
    "# split into train/test sets\n",
    "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2)\n",
    "# generate a no skill prediction (majority class)\n",
    "ns_probs = [0 for _ in range(len(testy))]\n",
    "# fit a model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(trainX, trainy)\n",
    "# predict probabilities\n",
    "lr_probs = model.predict_proba(testX)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# calculate scores\n",
    "ns_auc = roc_auc_score(testy, ns_probs)\n",
    "lr_auc = roc_auc_score(testy, lr_probs)\n",
    "# summarize scores\n",
    "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "ns_fpr, ns_tpr, _ = roc_curve(testy, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(testy, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "plt.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "\n",
    "# Image\n",
    "run.log_image('ROC', path=None, plot=plt, description='')\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the run\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## 4. Model\n",
    "\n",
    "### 4.1 Register Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['./model/churn-model.pkl']"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# customer ages\n",
    "X_train = np.array([50, 17, 35, 23, 28, 40, 31, 29, 19, 62])\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "# churn y/n\n",
    "y_train = [\"yes\", \"no\", \"no\", \"no\", \"yes\", \"yes\", \"yes\", \"no\", \"no\", \"yes\"]\n",
    "\n",
    "clf = svm.SVC(gamma=0.001, C=100.)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(value=clf, filename=\"./outputs/churn-model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Registering model churn-model-test\n"
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model.register(workspace=ws, model_path=\"./model/churn-model.pkl\", model_name=\"churn-model-test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'c:\\\\Users\\\\jebaeuer\\\\Desktop\\\\repo\\\\azure-machine-learning-service\\\\churn-model.pkl'"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "import os\n",
    "\n",
    "model = Model(workspace=ws, name=\"churn-model-test\")\n",
    "model.download(target_dir=os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Delete Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## 5. ComputeTarget, RunConfiguration, and ScriptRunConfig\n",
    "\n",
    "### 5.1 Setting up an AmlCompute (child class of ComputeTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.compute import AmlCompute\n",
    "list_vms = AmlCompute.supported_vmsizes(workspace=ws)\n",
    "# list_vms\n",
    "compute_config = RunConfiguration()\n",
    "compute_config.target = \"amlcompute\"\n",
    "compute_config.amlcompute.vm_size = \"STANDARD_D1_V2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "dependencies = CondaDependencies()\n",
    "dependencies.add_pip_package(\"scikit-learn\")\n",
    "dependencies.add_pip_package(\"numpy==1.15.4\")\n",
    "compute_config.environment.python.conda_dependencies = dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "             | 3.1 MB    |            |   0% \u001b[0m\u001b[91m\ntk-8.6.8             | 3.1 MB    | #######6   |  77% \u001b[0m\u001b[91m\ntk-8.6.8             | 3.1 MB    | ########9  |  90% \u001b[0m\u001b[91m\ntk-8.6.8             | 3.1 MB    | #########9 | 100% \u001b[0m\u001b[91m\ntk-8.6.8             | 3.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n\nsqlite-3.23.1        | 1.5 MB    |            |   0% \u001b[0m\u001b[91m\nsqlite-3.23.1        | 1.5 MB    | #######9   |  80% \u001b[0m\u001b[91m\nsqlite-3.23.1        | 1.5 MB    | ########## | 100% \u001b[0m\u001b[91m\n\nncurses-6.0          | 907 KB    |            |   0% \u001b[0m\u001b[91m\nncurses-6.0          | 907 KB    | #######9   |  79% \u001b[0m\u001b[91m\nncurses-6.0          | 907 KB    | #########1 |  92% \u001b[0m\u001b[91m\nncurses-6.0          | 907 KB    | ########## | 100% \u001b[0m\u001b[91m\n\ncertifi-2020.4.5.1   | 159 KB    |            |   0% \u001b[0m\u001b[91m\ncertifi-2020.4.5.1   | 159 KB    | ########## | 100% \u001b[0m\u001b[91m\n\nwheel-0.34.2         | 49 KB     |            |   0% \u001b[0m\u001b[91m\nwheel-0.34.2         | 49 KB     | ########## | 100% \u001b[0m\u001b[91m\n\nzlib-1.2.11          | 120 KB    |            |   0% \u001b[0m\u001b[91m\nzlib-1.2.11          | 120 KB    | ########## | 100% \u001b[0m\u001b[91m\n\npip-20.0.2           | 1.9 MB    |            |   0% \u001b[0m\u001b[91m\npip-20.0.2           | 1.9 MB    | #######8   |  78% \u001b[0m\u001b[91m\npip-20.0.2           | 1.9 MB    | #########5 |  95% \u001b[0m\u001b[91m\npip-20.0.2           | 1.9 MB    | ########## | 100% \u001b[0m\u001b[91m\n\nca-certificates-2020 | 132 KB    |            |   0% \u001b[0m\u001b[91m\nca-certificates-2020 | 132 KB    | ########## | 100% \u001b[0m\u001b[91m\n\nreadline-7.0         | 387 KB    |            |   0% \u001b[0m\u001b[91m\nreadline-7.0         | 387 KB    | #########  |  91% \u001b[0m\u001b[91m\nreadline-7.0         | 387 KB    | ########## | 100% \u001b[0m\nDownloading and Extracting Packages\nPreparing transaction: ...working... done\nVerifying transaction: ...working... done\nExecuting transaction: ...working... done\nCollecting azureml-defaults\n  Downloading azureml_defaults-1.6.0-py3-none-any.whl (3.0 kB)\nCollecting scikit-learn\n  Downloading scikit_learn-0.23.1-cp36-cp36m-manylinux1_x86_64.whl (6.8 MB)\nCollecting numpy==1.15.4\n  Downloading numpy-1.15.4-cp36-cp36m-manylinux1_x86_64.whl (13.9 MB)\nCollecting azureml-core~=1.6.0\n  Downloading azureml_core-1.6.0.post1-py3-none-any.whl (1.3 MB)\nCollecting gunicorn==19.9.0\n  Downloading gunicorn-19.9.0-py2.py3-none-any.whl (112 kB)\nCollecting werkzeug==0.16.1\n  Downloading Werkzeug-0.16.1-py2.py3-none-any.whl (327 kB)\nCollecting azureml-dataprep[fuse]<1.7.0a,>=1.6.2a\n  Downloading azureml_dataprep-1.6.3-py3-none-any.whl (27.8 MB)\nCollecting flask==1.0.3\n  Downloading Flask-1.0.3-py2.py3-none-any.whl (92 kB)\nCollecting configparser==3.7.4\n  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\nCollecting azureml-model-management-sdk==1.0.1b6.post1\n  Downloading azureml_model_management_sdk-1.0.1b6.post1-py2.py3-none-any.whl (130 kB)\nCollecting json-logging-py==0.2\n  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\nCollecting applicationinsights>=0.11.7\n  Downloading applicationinsights-0.11.9-py2.py3-none-any.whl (58 kB)\nCollecting scipy>=0.19.1\n  Downloading scipy-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (26.1 MB)\nCollecting threadpoolctl>=2.0.0\n  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\nCollecting joblib>=0.11\n  Downloading joblib-0.15.1-py3-none-any.whl (298 kB)\nCollecting azure-mgmt-storage>=1.5.0\n  Downloading azure_mgmt_storage-10.0.0-py2.py3-none-any.whl (532 kB)\nCollecting docker\n  Downloading docker-4.2.1-py2.py3-none-any.whl (143 kB)\nCollecting contextlib2\n  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\nCollecting msrestazure>=0.4.33\n  Downloading msrestazure-0.6.3-py2.py3-none-any.whl (40 kB)\nCollecting requests>=2.19.1\n  Downloading requests-2.23.0-py2.py3-none-any.whl (58 kB)\nCollecting urllib3>=1.23\n  Downloading urllib3-1.25.9-py2.py3-none-any.whl (126 kB)\nCollecting python-dateutil>=2.7.3\n  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\nCollecting jsonpickle\n  Downloading jsonpickle-1.4.1-py2.py3-none-any.whl (36 kB)\nCollecting azure-mgmt-network~=10.0\n  Downloading azure_mgmt_network-10.2.0-py2.py3-none-any.whl (8.6 MB)\nCollecting azure-mgmt-authorization>=0.40.0\n  Downloading azure_mgmt_authorization-0.60.0-py2.py3-none-any.whl (82 kB)\nCollecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*\n  Downloading cryptography-2.9.2-cp35-abi3-manylinux2010_x86_64.whl (2.7 MB)\nCollecting SecretStorage\n  Downloading SecretStorage-3.1.2-py3-none-any.whl (14 kB)\nCollecting msrest>=0.5.1\n  Downloading msrest-0.6.15-py2.py3-none-any.whl (84 kB)\nCollecting adal>=1.2.0\n  Downloading adal-1.2.4-py2.py3-none-any.whl (55 kB)\nCollecting jmespath\n  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\nCollecting pyopenssl\n  Downloading pyOpenSSL-19.1.0-py2.py3-none-any.whl (53 kB)\nCollecting azure-mgmt-keyvault>=0.40.0\n  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\nCollecting azure-common>=1.1.12\n  Downloading azure_common-1.1.25-py2.py3-none-any.whl (12 kB)\nCollecting azure-graphrbac>=0.40.0\n  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\nCollecting ruamel.yaml>0.16.7\n  Downloading ruamel.yaml-0.16.10-py2.py3-none-any.whl (111 kB)\nCollecting ndg-httpsclient\n  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\nCollecting pathspec\n  Downloading pathspec-0.8.0-py2.py3-none-any.whl (28 kB)\nCollecting azure-mgmt-containerregistry>=2.0.0\n  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\nCollecting pytz\n  Downloading pytz-2020.1-py2.py3-none-any.whl (510 kB)\nCollecting backports.tempfile\n  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\nCollecting azure-mgmt-resource>=1.2.1\n  Downloading azure_mgmt_resource-10.0.0-py2.py3-none-any.whl (809 kB)\nCollecting PyJWT\n  Downloading PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\nCollecting azureml-dataprep-native<15.0.0,>=14.1.0\n  Downloading azureml_dataprep_native-14.2.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\nCollecting cloudpickle>=1.1.0\n  Downloading cloudpickle-1.4.1-py3-none-any.whl (26 kB)\nCollecting azure-identity<1.3.0,>=1.2.0\n  Downloading azure_identity-1.2.0-py2.py3-none-any.whl (58 kB)\nCollecting dotnetcore2>=2.1.14\n  Downloading dotnetcore2-2.1.14-py3-none-manylinux1_x86_64.whl (29.3 MB)\nCollecting fusepy>=3.0.1; extra == \"fuse\"\n  Downloading fusepy-3.0.1.tar.gz (11 kB)\nCollecting Jinja2>=2.10\n  Downloading Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\nCollecting click>=5.1\n  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\nCollecting itsdangerous>=0.24\n  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\nCollecting pandas>=0.20.2\n  Downloading pandas-1.0.4-cp36-cp36m-manylinux1_x86_64.whl (10.1 MB)\nCollecting dill>=0.2.7.1\n  Downloading dill-0.3.1.1.tar.gz (151 kB)\nCollecting liac-arff>=2.1.1\n  Downloading liac-arff-2.4.0.tar.gz (15 kB)\nCollecting six>=1.10\n  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\nCollecting websocket-client>=0.32.0\n  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\nRequirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_d852ff2f6fa902aedd9acf4666393425/lib/python3.6/site-packages (from requests>=2.19.1->azureml-core~=1.6.0->azureml-defaults->-r /azureml-environment-setup/condaenv.u0np3jxv.requirements.txt (line 1)) (2020.4.5.1)\nCollecting idna<3,>=2.5\n  Downloading idna-2.9-py2.py3-none-any.whl (58 kB)\nCollecting chardet<4,>=3.0.2\n  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\nCollecting importlib-metadata\n  Downloading importlib_metadata-1.6.1-py2.py3-none-any.whl (31 kB)\nCollecting cffi!=1.11.3,>=1.8\n  Downloading cffi-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (399 kB)\nCollecting jeepney>=0.4.2\n  Downloading jeepney-0.4.3-py3-none-any.whl (21 kB)\nCollecting requests-oauthlib>=0.5.0\n  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\nCollecting isodate>=0.6.0\n  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\nCollecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.9\"\n  Downloading ruamel.yaml.clib-0.2.0-cp36-cp36m-manylinux1_x86_64.whl (548 kB)\nCollecting pyasn1>=0.1.1\n  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\nCollecting backports.weakref\n  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\nCollecting msal<2.0.0,>=1.0.0\n  Downloading msal-1.3.0-py2.py3-none-any.whl (48 kB)\nCollecting azure-core<2.0.0,>=1.0.0\n  Downloading azure_core-1.6.0-py2.py3-none-any.whl (120 kB)\nCollecting msal-extensions~=0.1.3\n  Downloading msal_extensions-0.1.3-py2.py3-none-any.whl (9.0 kB)\nCollecting distro>=1.2.0\n  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\nCollecting MarkupSafe>=0.23\n  Downloading MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (27 kB)\nCollecting zipp>=0.5\n  Downloading zipp-3.1.0-py3-none-any.whl (4.9 kB)\nCollecting pycparser\n  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\nCollecting oauthlib>=3.0.0\n  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\nCollecting portalocker~=1.0\n  Downloading portalocker-1.7.0-py2.py3-none-any.whl (14 kB)\nBuilding wheels for collected packages: json-logging-py, fusepy, dill, liac-arff\n  Building wheel for json-logging-py (setup.py): started\n  Building wheel for json-logging-py (setup.py): finished with status 'done'\n  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3923 sha256=85beeacbe41f793c5fd32bc23a2bf94d1b30de6228f23bb6ee28f1e190b5a7b6\n  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\n  Building wheel for fusepy (setup.py): started\n  Building wheel for fusepy (setup.py): finished with status 'done'\n  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10503 sha256=e377a2c880fb6cb55c1b99e29ba4bf6f73eb6131f8017e795eabc812f8e0a817\n  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n  Building wheel for dill (setup.py): started\n  Building wheel for dill (setup.py): finished with status 'done'\n  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78530 sha256=ac513903834b214ab4efd49e8922be086f55f7c25d11b4725e95a56ebb8b5305\n  Stored in directory: /root/.cache/pip/wheels/09/84/74/d2b4feb9ac9488bc83c475cb2cbe8e8b7d9cea8320d32f3787\n  Building wheel for liac-arff (setup.py): started\n  Building wheel for liac-arff (setup.py): finished with status 'done'\n  Created wheel for liac-arff: filename=liac_arff-2.4.0-py3-none-any.whl size=13333 sha256=0b440f2bd6bd6f51a2e0ca9ae013f6a5834de95f6b26889de1260d687d44c639\n  Stored in directory: /root/.cache/pip/wheels/ba/2a/e1/6f7be2e2ea150e2486bff64fd6f0670f4f35f4c8f31c819fb8\nSuccessfully built json-logging-py fusepy dill liac-arff\nInstalling collected packages: urllib3, idna, chardet, requests, six, pycparser, cffi, cryptography, PyJWT, python-dateutil, adal, oauthlib, requests-oauthlib, isodate, msrest, msrestazure, azure-common, azure-mgmt-storage, websocket-client, docker, contextlib2, zipp, importlib-metadata, jsonpickle, azure-mgmt-network, azure-mgmt-authorization, jeepney, SecretStorage, jmespath, pyopenssl, azure-mgmt-keyvault, azure-graphrbac, ruamel.yaml.clib, ruamel.yaml, pyasn1, ndg-httpsclient, pathspec, azure-mgmt-containerregistry, pytz, backports.weakref, backports.tempfile, azure-mgmt-resource, azureml-core, gunicorn, werkzeug, azureml-dataprep-native, cloudpickle, msal, azure-core, portalocker, msal-extensions, azure-identity, distro, dotnetcore2, fusepy, azureml-dataprep, MarkupSafe, Jinja2, click, itsdangerous, flask, configparser, numpy, pandas, dill, liac-arff, azureml-model-management-sdk, json-logging-py, applicationinsights, azureml-defaults, scipy, threadpoolctl, joblib, scikit-learn\n\nSuccessfully installed Jinja2-2.11.2 MarkupSafe-1.1.1 PyJWT-1.7.1 SecretStorage-3.1.2 adal-1.2.4 applicationinsights-0.11.9 azure-common-1.1.25 azure-core-1.6.0 azure-graphrbac-0.61.1 azure-identity-1.2.0 azure-mgmt-authorization-0.60.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-network-10.2.0 azure-mgmt-resource-10.0.0 azure-mgmt-storage-10.0.0 azureml-core-1.6.0.post1 azureml-dataprep-1.6.3 azureml-dataprep-native-14.2.0 azureml-defaults-1.6.0 azureml-model-management-sdk-1.0.1b6.post1 backports.tempfile-1.0 backports.weakref-1.0.post1 cffi-1.14.0 chardet-3.0.4 click-7.1.2 cloudpickle-1.4.1 configparser-3.7.4 contextlib2-0.6.0.post1 cryptography-2.9.2 dill-0.3.1.1 distro-1.5.0 docker-4.2.1 dotnetcore2-2.1.14 flask-1.0.3 fusepy-3.0.1 gunicorn-19.9.0 idna-2.9 importlib-metadata-1.6.1 isodate-0.6.0 itsdangerous-1.1.0 jeepney-0.4.3 jmespath-0.10.0 joblib-0.15.1 json-logging-py-0.2 jsonpickle-1.4.1 liac-arff-2.4.0 msal-1.3.0 msal-extensions-0.1.3 msrest-0.6.15 msrestazure-0.6.3 ndg-httpsclient-0.5.1 numpy-1.15.4 oauthlib-3.1.0 pandas-1.0.4 pathspec-0.8.0 portalocker-1.7.0 pyasn1-0.4.8 pycparser-2.20 pyopenssl-19.1.0 python-dateutil-2.8.1 pytz-2020.1 requests-2.23.0 requests-oauthlib-1.3.0 ruamel.yaml-0.16.10 ruamel.yaml.clib-0.2.0 scikit-learn-0.23.1 scipy-1.4.1 six-1.15.0 threadpoolctl-2.1.0 urllib3-1.25.9 websocket-client-0.57.0 werkzeug-0.16.1 zipp-3.1.0\n#\n# To activate this environment, use:\n# > source activate /azureml-envs/azureml_d852ff2f6fa902aedd9acf4666393425\n#\n# To deactivate an active environment, use:\n# > source deactivate\n#\n\n\u001b[91m\n\u001b[0m\nRemoving intermediate container b77a5408a2c1\n ---> 4de3807f65a6\nStep 9/15 : ENV PATH /azureml-envs/azureml_d852ff2f6fa902aedd9acf4666393425/bin:$PATH\n ---> Running in e6a5174f0814\nRemoving intermediate container e6a5174f0814\n ---> dc9ab0f92916\nStep 10/15 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_d852ff2f6fa902aedd9acf4666393425\n ---> Running in 2444890bd039\nRemoving intermediate container 2444890bd039\n ---> 61ebd7e9c35a\nStep 11/15 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_d852ff2f6fa902aedd9acf4666393425/lib:$LD_LIBRARY_PATH\n ---> Running in 8bebf3e4c73b\nRemoving intermediate container 8bebf3e4c73b\n ---> a23624460a5f\nStep 12/15 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n ---> effc8299b873\nStep 13/15 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n ---> Running in b951de7631a5\nRemoving intermediate container b951de7631a5\n ---> 8e9846e62ce7\nStep 14/15 : ENV AZUREML_ENVIRONMENT_IMAGE True\n ---> Running in d4602a0063ed\nRemoving intermediate container d4602a0063ed\n ---> 0c57348d28f9\nStep 15/15 : CMD [\"bash\"]\n ---> Running in 6d31af4368cd\nRemoving intermediate container 6d31af4368cd\n ---> 1b5f7c33f117\nSuccessfully built 1b5f7c33f117\nSuccessfully tagged datascience5f0bbf8b.azurecr.io/azureml/azureml_0e1bd70aac9a80581aab00a3c5449090:latest\n2020/06/08 13:28:34 Successfully executed container: acb_step_0\n2020/06/08 13:28:34 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n2020/06/08 13:28:34 Pushing image: datascience5f0bbf8b.azurecr.io/azureml/azureml_0e1bd70aac9a80581aab00a3c5449090:latest, attempt 1\nThe push refers to repository [datascience5f0bbf8b.azurecr.io/azureml/azureml_0e1bd70aac9a80581aab00a3c5449090]\n968a79015471: Preparing\n850c7b032ef5: Preparing\n2ef1bbc110b8: Preparing\na8df2aac2f0f: Preparing\nc323b69e974c: Preparing\ncced827a6138: Preparing\ne1171d4d60ca: Preparing\n6ef1a8ae63b7: Preparing\n85389f9ead9e: Preparing\nf2608f66a0e3: Preparing\n0e259b09e5f4: Preparing\n340dc32eb998: Preparing\ndf18b66efaa6: Preparing\nccdb13a20bf2: Preparing\n9513cdf4e497: Preparing\n7f083f9454c0: Preparing\n29f36b5893dc: Preparing\nf2608f66a0e3: Waiting\n0e259b09e5f4: Waiting\n340dc32eb998: Waiting\ndf18b66efaa6: Waiting\nccdb13a20bf2: Waiting\n9513cdf4e497: Waiting\n7f083f9454c0: Waiting\n29f36b5893dc: Waiting\ne1171d4d60ca: Waiting\n6ef1a8ae63b7: Waiting\n85389f9ead9e: Waiting\ncced827a6138: Waiting\na8df2aac2f0f: Pushed\n968a79015471: Pushed\nc323b69e974c: Pushed\n2ef1bbc110b8: Pushed\ncced827a6138: Pushed\n6ef1a8ae63b7: Pushed\ne1171d4d60ca: Pushed\n\n340dc32eb998: Pushed\n0e259b09e5f4: Pushed\nccdb13a20bf2: Pushed\n9513cdf4e497: Pushed\n85389f9ead9e: Pushed\n7f083f9454c0: Pushed\nf2608f66a0e3: Pushed\n29f36b5893dc: Pushed\ndf18b66efaa6: Pushed\n850c7b032ef5: Pushed\nlatest: digest: sha256:f134272f00875040183e09f17d300ca3f72b2021c508004185471588d7b7797b size: 3883\n2020/06/08 13:30:01 Successfully pushed image: datascience5f0bbf8b.azurecr.io/azureml/azureml_0e1bd70aac9a80581aab00a3c5449090:latest\n2020/06/08 13:30:01 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 162.796549)\n2020/06/08 13:30:01 Populating digests for step ID: acb_step_0...\n2020/06/08 13:30:03 Successfully populated digests for step ID: acb_step_0\n2020/06/08 13:30:03 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 87.011636)\n2020/06/08 13:30:03 The following dependencies were found:\n2020/06/08 13:30:03 \n- image:\n    registry: datascience5f0bbf8b.azurecr.io\n    repository: azureml/azureml_0e1bd70aac9a80581aab00a3c5449090\n    tag: latest\n    digest: sha256:f134272f00875040183e09f17d300ca3f72b2021c508004185471588d7b7797b\n  runtime-dependency:\n    registry: mcr.microsoft.com\n    repository: azureml/base\n    tag: intelmpi2018.3-ubuntu16.04\n    digest: sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\n  git: {}\n\n\nRun ID: cb1 was successful after 4m17s\n\nStreaming azureml-logs/55_azureml-execution-tvmps_4b2a07b1f4e0cff1d733e9b3aab3ba76f5e1300d0a9d612669ec1681e951221a_d.txt\n========================================================================================================================\n\n2020-06-08T13:35:27Z Starting output-watcher...\n2020-06-08T13:35:27Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n\nStreaming azureml-logs/65_job_prep-tvmps_4b2a07b1f4e0cff1d733e9b3aab3ba76f5e1300d0a9d612669ec1681e951221a_d.txt\n===============================================================================================================\n\nEntering job preparation. Current time:2020-06-08T13:39:13.388984\nStarting job preparation. Current time:2020-06-08T13:39:14.267307\nExtracting the control code.\nfetching and extracting the control code on master node.\nRetrieving project from snapshot: c969ca13-71a1-4f0b-9b43-f31fa833caa3\nStarting the daemon thread to refresh tokens in background for process with pid = 47\nStarting project file download.\n\nStreaming azureml-logs/70_driver_log.txt\n========================================\n\n2020/06/08 13:39:18 Starting App Insight Logger for task:  runTaskLet\nEntering context manager injector. Current time:2020-06-08T13:39:20.674986\nStarting the daemon thread to refresh tokens in background for process with pid = 99\nEntering Run History Context Manager.\nPreparing to call script [ train.py ] with arguments: []\nAfter variable expansion, calling script [ train.py ] with arguments: []\n\n\nStreaming azureml-logs/75_job_post-tvmps_4b2a07b1f4e0cff1d733e9b3aab3ba76f5e1300d0a9d612669ec1681e951221a_d.txt\n===============================================================================================================\n\nEntering job release. Current time:2020-06-08T13:39:28.292529\nStarting job release. Current time:2020-06-08T13:39:29.377780\nLogging experiment finalizing status in history service.\nStarting the daemon thread to refresh tokens in background for process with pid = 124\nEntering context manager injector. Current time:2020-06-08T13:39:29.394661\nJob release is complete. Current time:2020-06-08T13:39:31.988243\n\nExecution Summary\n=================\nRunId: compute_target_test_1591622741_7ad2e8fd\nWeb View: https://ml.azure.com/experiments/compute_target_test/runs/compute_target_test_1591622741_7ad2e8fd?wsid=/subscriptions/29b64be4-867b-40ee-a259-b58b97bfc26f/resourcegroups/data-science/workspaces/data-science\n\nWarnings:\nThis compute target type doesn't support non-Docker runs; overriding run configuration to enable Docker.\nPlease enable Docker in the environment section of your run configuration to stop seeing this warning message.\n\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'runId': 'compute_target_test_1591622741_7ad2e8fd',\n 'target': 'amlcompute',\n 'status': 'Completed',\n 'startTimeUtc': '2020-06-08T13:35:23.074811Z',\n 'endTimeUtc': '2020-06-08T13:43:55.170439Z',\n 'warnings': [{'message': \"This compute target type doesn't support non-Docker runs; overriding run configuration to enable Docker.\\nPlease enable Docker in the environment section of your run configuration to stop seeing this warning message.\"}],\n 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n  'ContentSnapshotId': '6facd48f-3470-46aa-91fa-36ded65a53fc',\n  'azureml.git.repository_uri': 'https://github.com/jensbaeuerle/azure-machine-learning-service.git',\n  'mlflow.source.git.repoURL': 'https://github.com/jensbaeuerle/azure-machine-learning-service.git',\n  'azureml.git.branch': 'master',\n  'mlflow.source.git.branch': 'master',\n  'azureml.git.commit': '21d855365a9dcd9c0e30699b17da462ee21f3d33',\n  'mlflow.source.git.commit': '21d855365a9dcd9c0e30699b17da462ee21f3d33',\n  'azureml.git.dirty': 'False',\n  'ProcessInfoFile': 'azureml-logs/process_info.json',\n  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n 'inputDatasets': [],\n 'runDefinition': {'script': 'train.py',\n  'useAbsolutePath': False,\n  'arguments': [],\n  'sourceDirectoryDataStore': None,\n  'framework': 'Python',\n  'communicator': 'None',\n  'target': 'amlcompute',\n  'dataReferences': {},\n  'data': {},\n  'outputData': {},\n  'jobName': None,\n  'maxRunDurationSeconds': None,\n  'nodeCount': 1,\n  'environment': {'name': 'Experiment compute_target_test Environment',\n   'version': 'Autosave_2020-06-08T13:25:42Z_46d78067',\n   'python': {'interpreterPath': 'python',\n    'userManagedDependencies': False,\n    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n     'dependencies': ['python=3.6.2',\n      {'pip': ['azureml-defaults', 'scikit-learn', 'numpy==1.15.4']}],\n     'name': 'azureml_d852ff2f6fa902aedd9acf4666393425'},\n    'baseCondaEnvironment': None},\n   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04',\n    'baseDockerfile': None,\n    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n    'enabled': False,\n    'arguments': []},\n   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n   'inferencingStackVersion': None},\n  'history': {'outputCollection': True,\n   'directoriesToWatch': ['logs'],\n   'snapshotProject': True},\n  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n    'spark.yarn.maxAppAttempts': '1'}},\n  'parallelTask': {'maxRetriesPerWorker': 0,\n   'workerCountPerNode': 1,\n   'terminalExitCodes': None,\n   'configuration': {}},\n  'amlCompute': {'name': None,\n   'vmSize': 'STANDARD_D1_V2',\n   'retainCluster': False,\n   'clusterMaxNodeCount': None},\n  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n  'mpi': {'processCountPerNode': 1},\n  'hdi': {'yarnDeployMode': 'Cluster'},\n  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n  'exposedPorts': None,\n  'docker': {'useDocker': False,\n   'sharedVolumes': True,\n   'shmSize': '2g',\n   'arguments': []},\n  'cmk8sCompute': {'configuration': {}},\n  'itpCompute': {'configuration': {}},\n  'cmAksCompute': {'configuration': {}}},\n 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://datascience5220774494.blob.core.windows.net/azureml/ExperimentRun/dcid.compute_target_test_1591622741_7ad2e8fd/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=WcqlJpGqOJb84lSfZ1%2BFsw6u%2B2Jqvkmk%2BP1qB9QFl%2Fs%3D&st=2020-06-08T13%3A33%3A56Z&se=2020-06-08T21%3A43%3A56Z&sp=r',\n  'azureml-logs/55_azureml-execution-tvmps_4b2a07b1f4e0cff1d733e9b3aab3ba76f5e1300d0a9d612669ec1681e951221a_d.txt': 'https://datascience5220774494.blob.core.windows.net/azureml/ExperimentRun/dcid.compute_target_test_1591622741_7ad2e8fd/azureml-logs/55_azureml-execution-tvmps_4b2a07b1f4e0cff1d733e9b3aab3ba76f5e1300d0a9d612669ec1681e951221a_d.txt?sv=2019-02-02&sr=b&sig=o0k02Jk5iIfiNLNftkBUAJ8KYzeOgwtE8nsSVoJRiNo%3D&st=2020-06-08T13%3A33%3A56Z&se=2020-06-08T21%3A43%3A56Z&sp=r',\n  'azureml-logs/65_job_prep-tvmps_4b2a07b1f4e0cff1d733e9b3aab3ba76f5e1300d0a9d612669ec1681e951221a_d.txt': 'https://datascience5220774494.blob.core.windows.net/azureml/ExperimentRun/dcid.compute_target_test_1591622741_7ad2e8fd/azureml-logs/65_job_prep-tvmps_4b2a07b1f4e0cff1d733e9b3aab3ba76f5e1300d0a9d612669ec1681e951221a_d.txt?sv=2019-02-02&sr=b&sig=PehkT9EhrW8HoLeghbek8ns4OcRtL4rM8ji7HKndoG8%3D&st=2020-06-08T13%3A33%3A56Z&se=2020-06-08T21%3A43%3A56Z&sp=r',\n  'azureml-logs/70_driver_log.txt': 'https://datascience5220774494.blob.core.windows.net/azureml/ExperimentRun/dcid.compute_target_test_1591622741_7ad2e8fd/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=vrPOYIwAkn0B%2Bg6SOvveZ20tPQOZrY6PapIN%2F7358F8%3D&st=2020-06-08T13%3A33%3A56Z&se=2020-06-08T21%3A43%3A56Z&sp=r',\n  'azureml-logs/75_job_post-tvmps_4b2a07b1f4e0cff1d733e9b3aab3ba76f5e1300d0a9d612669ec1681e951221a_d.txt': 'https://datascience5220774494.blob.core.windows.net/azureml/ExperimentRun/dcid.compute_target_test_1591622741_7ad2e8fd/azureml-logs/75_job_post-tvmps_4b2a07b1f4e0cff1d733e9b3aab3ba76f5e1300d0a9d612669ec1681e951221a_d.txt?sv=2019-02-02&sr=b&sig=HKnHGTS57wyvVS3JNimXzfBziStzaJROrY4p%2BUgFkc8%3D&st=2020-06-08T13%3A33%3A56Z&se=2020-06-08T21%3A43%3A56Z&sp=r',\n  'azureml-logs/process_info.json': 'https://datascience5220774494.blob.core.windows.net/azureml/ExperimentRun/dcid.compute_target_test_1591622741_7ad2e8fd/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=gHGP3m11gGQUgH0zANm910fmbpz6fiEh%2FRBA98gWqzU%3D&st=2020-06-08T13%3A33%3A56Z&se=2020-06-08T21%3A43%3A56Z&sp=r',\n  'azureml-logs/process_status.json': 'https://datascience5220774494.blob.core.windows.net/azureml/ExperimentRun/dcid.compute_target_test_1591622741_7ad2e8fd/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=D0nn7%2FKxGBCjJC649w%2Fzlq8qqpApmUCSrYPy2qAPIfg%3D&st=2020-06-08T13%3A33%3A56Z&se=2020-06-08T21%3A43%3A56Z&sp=r',\n  'logs/azureml/99_azureml.log': 'https://datascience5220774494.blob.core.windows.net/azureml/ExperimentRun/dcid.compute_target_test_1591622741_7ad2e8fd/logs/azureml/99_azureml.log?sv=2019-02-02&sr=b&sig=aXymkIFJSGPxhwhH4rVedXSjlr8NOmhcdmC4dbXYmD4%3D&st=2020-06-08T13%3A33%3A56Z&se=2020-06-08T21%3A43%3A56Z&sp=r',\n  'logs/azureml/job_prep_azureml.log': 'https://datascience5220774494.blob.core.windows.net/azureml/ExperimentRun/dcid.compute_target_test_1591622741_7ad2e8fd/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=wxa3IzxmkRnlcNKHmeEebg5FgK2arefGX15dxmV14lE%3D&st=2020-06-08T13%3A33%3A56Z&se=2020-06-08T21%3A43%3A56Z&sp=r',\n  'logs/azureml/job_release_azureml.log': 'https://datascience5220774494.blob.core.windows.net/azureml/ExperimentRun/dcid.compute_target_test_1591622741_7ad2e8fd/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=jOSmEMjcwHNy7gh2ZtKKCyXTPNFgTG3f2vaiLDEnpwY%3D&st=2020-06-08T13%3A33%3A56Z&se=2020-06-08T21%3A43%3A56Z&sp=r'}}"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "script_run_config = ScriptRunConfig(source_directory=os.getcwd(), script=\"train.py\", run_config=compute_config)\n",
    "experiment = Experiment(workspace=ws, name=\"compute_target_test\")\n",
    "run = experiment.submit(config=script_run_config)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Create a Compute Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Creating\nSucceeded\nAmlCompute wait for completion finished\nMinimum number of nodes requested have been provisioned\n"
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Choose a name for your CPU cluster\n",
    "cpu_cluster_name = \"cpu-cluster\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\n",
    "                                                            max_nodes=4)\n",
    "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "cpu_cluster.wait_for_completion(show_output=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bitbaseconda7dbc791cb36749bd83e95b68b2a99bb5",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}